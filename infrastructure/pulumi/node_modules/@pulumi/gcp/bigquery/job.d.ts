import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";
/**
 * Jobs are actions that BigQuery runs on your behalf to load data, export data, query data, or copy data.
 * Once a BigQuery job is created, it cannot be changed or deleted.
 *
 * To get more information about Job, see:
 *
 * * [API documentation](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs)
 * * How-to Guides
 *     * [BigQuery Jobs Intro](https://cloud.google.com/bigquery/docs/jobs-overview)
 *
 * ## Example Usage
 *
 * ### Bigquery Job Query
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const bar = new gcp.bigquery.Dataset("bar", {
 *     datasetId: "job_query_dataset",
 *     friendlyName: "test",
 *     description: "This is a test description",
 *     location: "US",
 * });
 * const foo = new gcp.bigquery.Table("foo", {
 *     deletionProtection: false,
 *     datasetId: bar.datasetId,
 *     tableId: "job_query_table",
 * });
 * const job = new gcp.bigquery.Job("job", {
 *     jobId: "job_query",
 *     labels: {
 *         "example-label": "example-value",
 *     },
 *     query: {
 *         query: "SELECT state FROM [lookerdata:cdc.project_tycho_reports]",
 *         destinationTable: {
 *             projectId: foo.project,
 *             datasetId: foo.datasetId,
 *             tableId: foo.tableId,
 *         },
 *         allowLargeResults: true,
 *         flattenResults: true,
 *         scriptOptions: {
 *             keyResultStatement: "LAST",
 *         },
 *     },
 * });
 * ```
 * ### Bigquery Job Query Table Reference
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const bar = new gcp.bigquery.Dataset("bar", {
 *     datasetId: "job_query_dataset",
 *     friendlyName: "test",
 *     description: "This is a test description",
 *     location: "US",
 * });
 * const foo = new gcp.bigquery.Table("foo", {
 *     deletionProtection: false,
 *     datasetId: bar.datasetId,
 *     tableId: "job_query_table",
 * });
 * const job = new gcp.bigquery.Job("job", {
 *     jobId: "job_query",
 *     labels: {
 *         "example-label": "example-value",
 *     },
 *     query: {
 *         query: "SELECT state FROM [lookerdata:cdc.project_tycho_reports]",
 *         destinationTable: {
 *             tableId: foo.id,
 *         },
 *         defaultDataset: {
 *             datasetId: bar.id,
 *         },
 *         allowLargeResults: true,
 *         flattenResults: true,
 *         scriptOptions: {
 *             keyResultStatement: "LAST",
 *         },
 *     },
 * });
 * ```
 * ### Bigquery Job Load
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const bar = new gcp.bigquery.Dataset("bar", {
 *     datasetId: "job_load_dataset",
 *     friendlyName: "test",
 *     description: "This is a test description",
 *     location: "US",
 * });
 * const foo = new gcp.bigquery.Table("foo", {
 *     deletionProtection: false,
 *     datasetId: bar.datasetId,
 *     tableId: "job_load_table",
 * });
 * const job = new gcp.bigquery.Job("job", {
 *     jobId: "job_load",
 *     labels: {
 *         my_job: "load",
 *     },
 *     load: {
 *         sourceUris: ["gs://cloud-samples-data/bigquery/us-states/us-states-by-date.csv"],
 *         destinationTable: {
 *             projectId: foo.project,
 *             datasetId: foo.datasetId,
 *             tableId: foo.tableId,
 *         },
 *         skipLeadingRows: 1,
 *         schemaUpdateOptions: [
 *             "ALLOW_FIELD_RELAXATION",
 *             "ALLOW_FIELD_ADDITION",
 *         ],
 *         writeDisposition: "WRITE_APPEND",
 *         autodetect: true,
 *     },
 * });
 * ```
 * ### Bigquery Job Load Geojson
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const project = "my-project-name";
 * const bucket = new gcp.storage.Bucket("bucket", {
 *     name: `${project}-bq-geojson`,
 *     location: "US",
 *     uniformBucketLevelAccess: true,
 * });
 * const object = new gcp.storage.BucketObject("object", {
 *     name: "geojson-data.jsonl",
 *     bucket: bucket.name,
 *     content: `{"type":"Feature","properties":{"continent":"Europe","region":"Scandinavia"},"geometry":{"type":"Polygon","coordinates":[[[-30.94,53.33],[33.05,53.33],[33.05,71.86],[-30.94,71.86],[-30.94,53.33]]]}}
 * {"type":"Feature","properties":{"continent":"Africa","region":"West Africa"},"geometry":{"type":"Polygon","coordinates":[[[-23.91,0],[11.95,0],[11.95,18.98],[-23.91,18.98],[-23.91,0]]]}}
 * `,
 * });
 * const bar = new gcp.bigquery.Dataset("bar", {
 *     datasetId: "job_load_dataset",
 *     friendlyName: "test",
 *     description: "This is a test description",
 *     location: "US",
 * });
 * const foo = new gcp.bigquery.Table("foo", {
 *     deletionProtection: false,
 *     datasetId: bar.datasetId,
 *     tableId: "job_load_table",
 * });
 * const job = new gcp.bigquery.Job("job", {
 *     jobId: "job_load",
 *     labels: {
 *         my_job: "load",
 *     },
 *     load: {
 *         sourceUris: [pulumi.interpolate`gs://${object.bucket}/${object.name}`],
 *         destinationTable: {
 *             projectId: foo.project,
 *             datasetId: foo.datasetId,
 *             tableId: foo.tableId,
 *         },
 *         writeDisposition: "WRITE_TRUNCATE",
 *         autodetect: true,
 *         sourceFormat: "NEWLINE_DELIMITED_JSON",
 *         jsonExtension: "GEOJSON",
 *     },
 * }, {
 *     dependsOn: [object],
 * });
 * ```
 * ### Bigquery Job Load Parquet
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const test = new gcp.storage.Bucket("test", {
 *     name: "job_load_bucket",
 *     location: "US",
 *     uniformBucketLevelAccess: true,
 * });
 * const testBucketObject = new gcp.storage.BucketObject("test", {
 *     name: "job_load_bucket_object",
 *     source: new pulumi.asset.FileAsset("./test-fixtures/test.parquet.gzip"),
 *     bucket: test.name,
 * });
 * const testDataset = new gcp.bigquery.Dataset("test", {
 *     datasetId: "job_load_dataset",
 *     friendlyName: "test",
 *     description: "This is a test description",
 *     location: "US",
 * });
 * const testTable = new gcp.bigquery.Table("test", {
 *     deletionProtection: false,
 *     tableId: "job_load_table",
 *     datasetId: testDataset.datasetId,
 * });
 * const job = new gcp.bigquery.Job("job", {
 *     jobId: "job_load",
 *     labels: {
 *         my_job: "load",
 *     },
 *     load: {
 *         sourceUris: [pulumi.interpolate`gs://${testBucketObject.bucket}/${testBucketObject.name}`],
 *         destinationTable: {
 *             projectId: testTable.project,
 *             datasetId: testTable.datasetId,
 *             tableId: testTable.tableId,
 *         },
 *         schemaUpdateOptions: [
 *             "ALLOW_FIELD_RELAXATION",
 *             "ALLOW_FIELD_ADDITION",
 *         ],
 *         writeDisposition: "WRITE_APPEND",
 *         sourceFormat: "PARQUET",
 *         autodetect: true,
 *         parquetOptions: {
 *             enumAsString: true,
 *             enableListInference: true,
 *         },
 *     },
 * });
 * ```
 * ### Bigquery Job Copy
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const count = 2;
 * const sourceDataset: gcp.bigquery.Dataset[] = [];
 * for (const range = {value: 0}; range.value < count; range.value++) {
 *     sourceDataset.push(new gcp.bigquery.Dataset(`source-${range.value}`, {
 *         datasetId: `job_copy_${range.value}_dataset`,
 *         friendlyName: "test",
 *         description: "This is a test description",
 *         location: "US",
 *     }));
 * }
 * const source: gcp.bigquery.Table[] = [];
 * for (const range = {value: 0}; range.value < count; range.value++) {
 *     source.push(new gcp.bigquery.Table(`source-${range.value}`, {
 *         deletionProtection: false,
 *         datasetId: sourceDataset[range.value].datasetId,
 *         tableId: `job_copy_${range.value}_table`,
 *         schema: `[
 *   {
 *     "name": "name",
 *     "type": "STRING",
 *     "mode": "NULLABLE"
 *   },
 *   {
 *     "name": "post_abbr",
 *     "type": "STRING",
 *     "mode": "NULLABLE"
 *   },
 *   {
 *     "name": "date",
 *     "type": "DATE",
 *     "mode": "NULLABLE"
 *   }
 * ]
 * `,
 *     }));
 * }
 * const destDataset = new gcp.bigquery.Dataset("dest", {
 *     datasetId: "job_copy_dest_dataset",
 *     friendlyName: "test",
 *     description: "This is a test description",
 *     location: "US",
 * });
 * const keyRing = new gcp.kms.KeyRing("key_ring", {
 *     name: "example-keyring",
 *     location: "global",
 * });
 * const cryptoKey = new gcp.kms.CryptoKey("crypto_key", {
 *     name: "example-key",
 *     keyRing: keyRing.id,
 * });
 * const project = gcp.organizations.getProject({
 *     projectId: "my-project-name",
 * });
 * const encryptRole = new gcp.projects.IAMMember("encrypt_role", {
 *     project: project.then(project => project.projectId),
 *     role: "roles/cloudkms.cryptoKeyEncrypterDecrypter",
 *     member: project.then(project => `serviceAccount:bq-${project.number}@bigquery-encryption.iam.gserviceaccount.com`),
 * });
 * const dest = new gcp.bigquery.Table("dest", {
 *     deletionProtection: false,
 *     datasetId: destDataset.datasetId,
 *     tableId: "job_copy_dest_table",
 *     schema: `[
 *   {
 *     "name": "name",
 *     "type": "STRING",
 *     "mode": "NULLABLE"
 *   },
 *   {
 *     "name": "post_abbr",
 *     "type": "STRING",
 *     "mode": "NULLABLE"
 *   },
 *   {
 *     "name": "date",
 *     "type": "DATE",
 *     "mode": "NULLABLE"
 *   }
 * ]
 * `,
 *     encryptionConfiguration: {
 *         kmsKeyName: cryptoKey.id,
 *     },
 * }, {
 *     dependsOn: [encryptRole],
 * });
 * const job = new gcp.bigquery.Job("job", {
 *     jobId: "job_copy",
 *     copy: {
 *         sourceTables: [
 *             {
 *                 projectId: source[0].project,
 *                 datasetId: source[0].datasetId,
 *                 tableId: source[0].tableId,
 *             },
 *             {
 *                 projectId: source[1].project,
 *                 datasetId: source[1].datasetId,
 *                 tableId: source[1].tableId,
 *             },
 *         ],
 *         destinationTable: {
 *             projectId: dest.project,
 *             datasetId: dest.datasetId,
 *             tableId: dest.tableId,
 *         },
 *         destinationEncryptionConfiguration: {
 *             kmsKeyName: cryptoKey.id,
 *         },
 *     },
 * }, {
 *     dependsOn: [encryptRole],
 * });
 * ```
 * ### Bigquery Job Extract
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as gcp from "@pulumi/gcp";
 *
 * const source_oneDataset = new gcp.bigquery.Dataset("source-one", {
 *     datasetId: "job_extract_dataset",
 *     friendlyName: "test",
 *     description: "This is a test description",
 *     location: "US",
 * });
 * const source_one = new gcp.bigquery.Table("source-one", {
 *     deletionProtection: false,
 *     datasetId: source_oneDataset.datasetId,
 *     tableId: "job_extract_table",
 *     schema: `[
 *   {
 *     "name": "name",
 *     "type": "STRING",
 *     "mode": "NULLABLE"
 *   },
 *   {
 *     "name": "post_abbr",
 *     "type": "STRING",
 *     "mode": "NULLABLE"
 *   },
 *   {
 *     "name": "date",
 *     "type": "DATE",
 *     "mode": "NULLABLE"
 *   }
 * ]
 * `,
 * });
 * const dest = new gcp.storage.Bucket("dest", {
 *     name: "job_extract_bucket",
 *     location: "US",
 *     forceDestroy: true,
 * });
 * const job = new gcp.bigquery.Job("job", {
 *     jobId: "job_extract",
 *     extract: {
 *         destinationUris: [pulumi.interpolate`${dest.url}/extract`],
 *         sourceTable: {
 *             projectId: source_one.project,
 *             datasetId: source_one.datasetId,
 *             tableId: source_one.tableId,
 *         },
 *         destinationFormat: "NEWLINE_DELIMITED_JSON",
 *         compression: "GZIP",
 *     },
 * });
 * ```
 *
 * ## Import
 *
 * Job can be imported using any of these accepted formats:
 *
 * * `projects/{{project}}/jobs/{{job_id}}/location/{{location}}`
 *
 * * `projects/{{project}}/jobs/{{job_id}}`
 *
 * * `{{project}}/{{job_id}}/{{location}}`
 *
 * * `{{job_id}}/{{location}}`
 *
 * * `{{project}}/{{job_id}}`
 *
 * * `{{job_id}}`
 *
 * When using the `pulumi import` command, Job can be imported using one of the formats above. For example:
 *
 * ```sh
 * $ pulumi import gcp:bigquery/job:Job default projects/{{project}}/jobs/{{job_id}}/location/{{location}}
 * ```
 *
 * ```sh
 * $ pulumi import gcp:bigquery/job:Job default projects/{{project}}/jobs/{{job_id}}
 * ```
 *
 * ```sh
 * $ pulumi import gcp:bigquery/job:Job default {{project}}/{{job_id}}/{{location}}
 * ```
 *
 * ```sh
 * $ pulumi import gcp:bigquery/job:Job default {{job_id}}/{{location}}
 * ```
 *
 * ```sh
 * $ pulumi import gcp:bigquery/job:Job default {{project}}/{{job_id}}
 * ```
 *
 * ```sh
 * $ pulumi import gcp:bigquery/job:Job default {{job_id}}
 * ```
 */
export declare class Job extends pulumi.CustomResource {
    /**
     * Get an existing Job resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    static get(name: string, id: pulumi.Input<pulumi.ID>, state?: JobState, opts?: pulumi.CustomResourceOptions): Job;
    /**
     * Returns true if the given object is an instance of Job.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    static isInstance(obj: any): obj is Job;
    /**
     * Copies a table.
     */
    readonly copy: pulumi.Output<outputs.bigquery.JobCopy | undefined>;
    /**
     * (Output)
     * All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
     */
    readonly effectiveLabels: pulumi.Output<{
        [key: string]: string;
    }>;
    /**
     * Configures an extract job.
     */
    readonly extract: pulumi.Output<outputs.bigquery.JobExtract | undefined>;
    /**
     * The ID of the job. The ID must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The maximum length is 1,024 characters.
     */
    readonly jobId: pulumi.Output<string>;
    /**
     * Job timeout in milliseconds. If this time limit is exceeded, BigQuery may attempt to terminate the job.
     */
    readonly jobTimeoutMs: pulumi.Output<string | undefined>;
    /**
     * (Output)
     * The type of the job.
     */
    readonly jobType: pulumi.Output<string>;
    /**
     * The labels associated with this job. You can use these to organize and group your jobs. **Note**: This field is
     * non-authoritative, and will only manage the labels present in your configuration. Please refer to the field
     * 'effective_labels' for all of the labels present on the resource.
     */
    readonly labels: pulumi.Output<{
        [key: string]: string;
    } | undefined>;
    /**
     * Configures a load job.
     */
    readonly load: pulumi.Output<outputs.bigquery.JobLoad | undefined>;
    /**
     * Specifies where the error occurred, if present.
     */
    readonly location: pulumi.Output<string | undefined>;
    readonly project: pulumi.Output<string>;
    /**
     * (Output)
     * The combination of labels configured directly on the resource
     * and default labels configured on the provider.
     */
    readonly pulumiLabels: pulumi.Output<{
        [key: string]: string;
    }>;
    /**
     * Configures a query job.
     */
    readonly query: pulumi.Output<outputs.bigquery.JobQuery | undefined>;
    /**
     * The status of this job. Examine this value when polling an asynchronous job to see if the job is complete.
     * Structure is documented below.
     */
    readonly statuses: pulumi.Output<outputs.bigquery.JobStatus[]>;
    /**
     * Email address of the user who ran the job.
     */
    readonly userEmail: pulumi.Output<string>;
    /**
     * Create a Job resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: JobArgs, opts?: pulumi.CustomResourceOptions);
}
/**
 * Input properties used for looking up and filtering Job resources.
 */
export interface JobState {
    /**
     * Copies a table.
     */
    copy?: pulumi.Input<inputs.bigquery.JobCopy>;
    /**
     * (Output)
     * All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
     */
    effectiveLabels?: pulumi.Input<{
        [key: string]: pulumi.Input<string>;
    }>;
    /**
     * Configures an extract job.
     */
    extract?: pulumi.Input<inputs.bigquery.JobExtract>;
    /**
     * The ID of the job. The ID must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The maximum length is 1,024 characters.
     */
    jobId?: pulumi.Input<string>;
    /**
     * Job timeout in milliseconds. If this time limit is exceeded, BigQuery may attempt to terminate the job.
     */
    jobTimeoutMs?: pulumi.Input<string>;
    /**
     * (Output)
     * The type of the job.
     */
    jobType?: pulumi.Input<string>;
    /**
     * The labels associated with this job. You can use these to organize and group your jobs. **Note**: This field is
     * non-authoritative, and will only manage the labels present in your configuration. Please refer to the field
     * 'effective_labels' for all of the labels present on the resource.
     */
    labels?: pulumi.Input<{
        [key: string]: pulumi.Input<string>;
    }>;
    /**
     * Configures a load job.
     */
    load?: pulumi.Input<inputs.bigquery.JobLoad>;
    /**
     * Specifies where the error occurred, if present.
     */
    location?: pulumi.Input<string>;
    project?: pulumi.Input<string>;
    /**
     * (Output)
     * The combination of labels configured directly on the resource
     * and default labels configured on the provider.
     */
    pulumiLabels?: pulumi.Input<{
        [key: string]: pulumi.Input<string>;
    }>;
    /**
     * Configures a query job.
     */
    query?: pulumi.Input<inputs.bigquery.JobQuery>;
    /**
     * The status of this job. Examine this value when polling an asynchronous job to see if the job is complete.
     * Structure is documented below.
     */
    statuses?: pulumi.Input<pulumi.Input<inputs.bigquery.JobStatus>[]>;
    /**
     * Email address of the user who ran the job.
     */
    userEmail?: pulumi.Input<string>;
}
/**
 * The set of arguments for constructing a Job resource.
 */
export interface JobArgs {
    /**
     * Copies a table.
     */
    copy?: pulumi.Input<inputs.bigquery.JobCopy>;
    /**
     * Configures an extract job.
     */
    extract?: pulumi.Input<inputs.bigquery.JobExtract>;
    /**
     * The ID of the job. The ID must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The maximum length is 1,024 characters.
     */
    jobId: pulumi.Input<string>;
    /**
     * Job timeout in milliseconds. If this time limit is exceeded, BigQuery may attempt to terminate the job.
     */
    jobTimeoutMs?: pulumi.Input<string>;
    /**
     * The labels associated with this job. You can use these to organize and group your jobs. **Note**: This field is
     * non-authoritative, and will only manage the labels present in your configuration. Please refer to the field
     * 'effective_labels' for all of the labels present on the resource.
     */
    labels?: pulumi.Input<{
        [key: string]: pulumi.Input<string>;
    }>;
    /**
     * Configures a load job.
     */
    load?: pulumi.Input<inputs.bigquery.JobLoad>;
    /**
     * Specifies where the error occurred, if present.
     */
    location?: pulumi.Input<string>;
    project?: pulumi.Input<string>;
    /**
     * Configures a query job.
     */
    query?: pulumi.Input<inputs.bigquery.JobQuery>;
}
